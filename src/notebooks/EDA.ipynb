{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratve Data Analysis\n",
    "\n",
    "This notebook includes an explorative data analysis  of the data sets for the following Common Vulnerabilities and Exposures *CVE's*:\n",
    " - CVE-2012-2122\n",
    " - CVE-2014-0160 \n",
    " - CVE-2017-12635-6\n",
    " - CVE-2018-3760\n",
    " - CVE-2019-5418\n",
    " - CVE-2020-9484\n",
    " - CVE-2020-13942\n",
    " - CVE-2020-23839\n",
    "\n",
    "For further information on each *CVE* and how the data sets were gathered please refer to https://github.com/LID-DS/LID-DS/wiki/Scenarios\n",
    "\n",
    "The main goal is to be able to record CVE-2020-18392 and detect DoS via CPU- and Memory-Usage https://cwe.mitre.org/data/definitions/674.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the data\n",
    "TRAIN = {}\n",
    "TEST = {}\n",
    "VALIDATION = {}\n",
    "\n",
    "path = \"../../data/interim/raw\"\n",
    "train = \"train_\"\n",
    "test = \"test_\"\n",
    "validation = \"validation_\"\n",
    "#  list of scenarios\n",
    "scenarios = [\n",
    "        'CVE-2012-2122',\n",
    "        'CVE-2014-0160',\n",
    "        'CVE-2017-7529',\n",
    "        'CVE-2017-12635_6',\n",
    "        'CVE-2018-3760',\n",
    "        'CVE-2019-5418',\n",
    "        'CVE-2020-9484',\n",
    "        'CVE-2020-13942',\n",
    "        'CVE-2020-23839'\n",
    "]\n",
    "\n",
    "for i in range(0,len(scenarios)):\n",
    "    TRAIN[scenarios[i]]= pd.read_pickle(path + \"/\" + train + scenarios[i] + \".pkl\")\n",
    "    TEST[scenarios[i]] = pd.read_pickle(path + \"/\" + test + scenarios[i] + \".pkl\")\n",
    "    VALIDATION[scenarios[i]] = pd.read_pickle(path + \"/\" + validation + scenarios[i] + \".pkl\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empyt list do concenate everything at the end\n",
    "dfs_train = []\n",
    "# create a column for each scenario name\n",
    "for key in TRAIN.keys():\n",
    "    TRAIN[key]['scenario'] = key\n",
    "    temp_df = TRAIN[key]\n",
    "    dfs_train.append(temp_df)\n",
    "TRAIN['ALL'] = pd.concat(dfs_train)\n",
    "\n",
    "dfs_test = []\n",
    "for key in TEST.keys():\n",
    "    TEST[key]['scenario'] = key\n",
    "    temp_df = TEST[key]\n",
    "    dfs_test.append(temp_df)\n",
    "TEST['ALL'] = pd.concat(dfs_test)\n",
    "\n",
    "dfs_validation = []\n",
    "for key in VALIDATION.keys():\n",
    "    VALIDATION[key]['scenario'] = key\n",
    "    temp_df = VALIDATION[key]\n",
    "    dfs_validation.append(temp_df)\n",
    "TEST['ALL'] = pd.concat(dfs_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a44f376b57d45d29a9912107e840c363fa2f9b3e8d3bc732ddcab4b4559e3e3b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('3.9.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
